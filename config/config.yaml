# ML-Agents Training Configuration for Player AI

behaviors:
  MyBehavior:  # This name must match the Behavior Name on your Agent's Behavior Parameters component in Unity
    trainer_type: ppo
    max_steps: 50000000
    checkpoint_interval: 300000
    time_horizon: 64
    summary_freq: 10000

    hyperparameters:
      batch_size: 64
      buffer_size: 20000
      learning_rate: 1e-4
      beta: 0.005 # Increased beta for more exploration
      epsilon: 0.15
      lambd: 0.95
      num_epoch: 3

    network_settings:
      normalize: true  # Normalize observations - highly recommended
      hidden_units: 256
      num_layers: 2
      # activation: relu  # Default is relu; uncomment if you want to be explicit

    reward_signals:
      extrinsic:  # Extrinsic reward from AddReward() calls in your Agent script
        strength: 1.0
        gamma: 0.99  # Discount factor for extrinsic rewards

      curiosity:  # Intrinsic Curiosity Module (ICM) - encourages exploration
        strength: 0.1  # Increased curiosity strength
        gamma: 0.99  # Discount factor for curiosity reward
        encoding_size: 128  # Size of the latent space for the curiosity module