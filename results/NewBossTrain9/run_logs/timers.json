{
    "name": "root",
    "gauges": {
        "MyBehavior.Policy.Entropy.mean": {
            "value": 4.5933918952941895,
            "min": 3.693242311477661,
            "max": 4.609004974365234,
            "count": 424
        },
        "MyBehavior.Policy.Entropy.sum": {
            "value": 46021.1953125,
            "min": 18421.4140625,
            "max": 46249.25,
            "count": 424
        },
        "MyBehavior.Step.mean": {
            "value": 4629976.0,
            "min": 399964.0,
            "max": 4629976.0,
            "count": 424
        },
        "MyBehavior.Step.sum": {
            "value": 4629976.0,
            "min": 399964.0,
            "max": 4629976.0,
            "count": 424
        },
        "MyBehavior.Policy.ExtrinsicValueEstimate.mean": {
            "value": 9.748091697692871,
            "min": 4.707159519195557,
            "max": 10.075567245483398,
            "count": 424
        },
        "MyBehavior.Policy.ExtrinsicValueEstimate.sum": {
            "value": 1559.6947021484375,
            "min": 442.0296630859375,
            "max": 1602.01513671875,
            "count": 424
        },
        "MyBehavior.Policy.CuriosityValueEstimate.mean": {
            "value": 0.28323155641555786,
            "min": 0.2551392614841461,
            "max": 2.176377296447754,
            "count": 424
        },
        "MyBehavior.Policy.CuriosityValueEstimate.sum": {
            "value": 45.317047119140625,
            "min": 40.906044006347656,
            "max": 338.145263671875,
            "count": 424
        },
        "MyBehavior.Environment.EpisodeLength.mean": {
            "value": 1238.2857142857142,
            "min": 704.0,
            "max": 1483.0,
            "count": 424
        },
        "MyBehavior.Environment.EpisodeLength.sum": {
            "value": 8668.0,
            "min": 4780.0,
            "max": 11452.0,
            "count": 424
        },
        "MyBehavior.Environment.CumulativeReward.mean": {
            "value": 129.2624876669475,
            "min": 58.790713453044496,
            "max": 157.0456578050341,
            "count": 424
        },
        "MyBehavior.Environment.CumulativeReward.sum": {
            "value": 904.8374136686325,
            "min": 302.9727571904659,
            "max": 1209.902782201767,
            "count": 424
        },
        "MyBehavior.Policy.ExtrinsicReward.mean": {
            "value": 129.2624876669475,
            "min": 58.790713453044496,
            "max": 157.0456578050341,
            "count": 424
        },
        "MyBehavior.Policy.ExtrinsicReward.sum": {
            "value": 904.8374136686325,
            "min": 302.9727571904659,
            "max": 1209.902782201767,
            "count": 424
        },
        "MyBehavior.Policy.CuriosityReward.mean": {
            "value": 3.7468924168497324,
            "min": 0.0,
            "max": 16.0372517252607,
            "count": 424
        },
        "MyBehavior.Policy.CuriosityReward.sum": {
            "value": 26.228246917948127,
            "min": 0.0,
            "max": 129.79555453546345,
            "count": 424
        },
        "MyBehavior.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 424
        },
        "MyBehavior.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 424
        },
        "MyBehavior.Losses.PolicyLoss.mean": {
            "value": 0.09813931928877918,
            "min": 0.09216440981898667,
            "max": 0.10591099676809991,
            "count": 211
        },
        "MyBehavior.Losses.PolicyLoss.sum": {
            "value": 0.09813931928877918,
            "min": 0.09216440981898667,
            "max": 0.10591099676809991,
            "count": 211
        },
        "MyBehavior.Losses.ValueLoss.mean": {
            "value": 0.2154032682490527,
            "min": 0.17335499982293853,
            "max": 0.4701291751810791,
            "count": 211
        },
        "MyBehavior.Losses.ValueLoss.sum": {
            "value": 0.2154032682490527,
            "min": 0.17335499982293853,
            "max": 0.4701291751810791,
            "count": 211
        },
        "MyBehavior.Policy.LearningRate.mean": {
            "value": 9.075555924445003e-05,
            "min": 9.075555924445003e-05,
            "max": 9.916944283055799e-05,
            "count": 211
        },
        "MyBehavior.Policy.LearningRate.sum": {
            "value": 9.075555924445003e-05,
            "min": 9.075555924445003e-05,
            "max": 9.916944283055799e-05,
            "count": 211
        },
        "MyBehavior.Policy.Epsilon.mean": {
            "value": 0.14537777500000001,
            "min": 0.14537777500000001,
            "max": 0.14958472100000006,
            "count": 211
        },
        "MyBehavior.Policy.Epsilon.sum": {
            "value": 0.14537777500000001,
            "min": 0.14537777500000001,
            "max": 0.14958472100000006,
            "count": 211
        },
        "MyBehavior.Policy.Beta.mean": {
            "value": 0.004538701944999999,
            "min": 0.004538701944999999,
            "max": 0.0049585551558,
            "count": 211
        },
        "MyBehavior.Policy.Beta.sum": {
            "value": 0.004538701944999999,
            "min": 0.004538701944999999,
            "max": 0.0049585551558,
            "count": 211
        },
        "MyBehavior.Losses.CuriosityForwardLoss.mean": {
            "value": 0.026986759973880954,
            "min": 0.024921929452799134,
            "max": 0.737795947427059,
            "count": 211
        },
        "MyBehavior.Losses.CuriosityForwardLoss.sum": {
            "value": 0.026986759973880954,
            "min": 0.024921929452799134,
            "max": 0.737795947427059,
            "count": 211
        },
        "MyBehavior.Losses.CuriosityInverseLoss.mean": {
            "value": 11.522910197575888,
            "min": 3.487079288758917,
            "max": 11.621570427196856,
            "count": 211
        },
        "MyBehavior.Losses.CuriosityInverseLoss.sum": {
            "value": 11.522910197575888,
            "min": 3.487079288758917,
            "max": 11.621570427196856,
            "count": 211
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1755797196",
        "python_version": "3.9.9 (tags/v3.9.9:ccb0e6a, Nov 15 2021, 18:08:50) [MSC v.1929 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\user1\\Unity 2D Platformer for Complete Beginners\\myenv39\\Scripts\\mlagents-learn config/config.yaml --run-id=NewBossTrain9 --time-scale=3 --resume",
        "mlagents_version": "0.26.0",
        "mlagents_envs_version": "0.26.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.7.0+cu118",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1755893377"
    },
    "total": 96181.4024588,
    "count": 1,
    "self": 0.03072400001110509,
    "children": {
        "run_training.setup": {
            "total": 0.4051311000000002,
            "count": 1,
            "self": 0.4051311000000002
        },
        "TrainerController.start_learning": {
            "total": 96180.9666037,
            "count": 1,
            "self": 109.97719939422677,
            "children": {
                "TrainerController._reset_env": {
                    "total": 29.037985900000002,
                    "count": 1,
                    "self": 29.037985900000002
                },
                "TrainerController.advance": {
                    "total": 96040.34571270578,
                    "count": 4239418,
                    "self": 103.33206981935655,
                    "children": {
                        "env_step": {
                            "total": 84137.91644659192,
                            "count": 4239418,
                            "self": 44419.35445118978,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 39646.076550901285,
                                    "count": 4239418,
                                    "self": 389.1900829928054,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 39256.88646790848,
                                            "count": 4239418,
                                            "self": 8610.858162302986,
                                            "children": {
                                                "TorchPolicy.sample_actions": {
                                                    "total": 30646.028305605494,
                                                    "count": 4239418,
                                                    "self": 30646.028305605494
                                                }
                                            }
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 72.4854445008507,
                                    "count": 4239417,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 95920.2842733057,
                                            "count": 4239417,
                                            "is_parallel": true,
                                            "self": 57610.97171302225,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.007433199999997697,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.0016464000000020462,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.005786799999995651,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.005786799999995651
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 38309.305127083455,
                                                    "count": 4239417,
                                                    "is_parallel": true,
                                                    "self": 435.62446428949625,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 403.56465850353834,
                                                            "count": 4239417,
                                                            "is_parallel": true,
                                                            "self": 403.56465850353834
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 35876.07789468342,
                                                            "count": 4239417,
                                                            "is_parallel": true,
                                                            "self": 35876.07789468342
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 1594.0381096070046,
                                                            "count": 4239417,
                                                            "is_parallel": true,
                                                            "self": 1036.1295336197613,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 557.9085759872432,
                                                                    "count": 8478834,
                                                                    "is_parallel": true,
                                                                    "self": 557.9085759872432
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 11799.097196294497,
                            "count": 4239417,
                            "self": 131.135850887762,
                            "children": {
                                "process_trajectory": {
                                    "total": 933.0132588067479,
                                    "count": 4239417,
                                    "self": 929.3890060067331,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 3.6242528000148013,
                                            "count": 14,
                                            "self": 3.6242528000148013
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 10734.948086599987,
                                    "count": 211,
                                    "self": 837.0258829008199,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 9897.922203699167,
                                            "count": 197826,
                                            "self": 9897.922203699167
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "TrainerController._save_models": {
                    "total": 1.6057056999998167,
                    "count": 1,
                    "self": 0.018938599998364225,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 1.5867671000014525,
                            "count": 1,
                            "self": 1.5867671000014525
                        }
                    }
                }
            }
        }
    }
}